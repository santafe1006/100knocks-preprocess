{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "zero2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPSeeUw62kXwGycrJJTL1uB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/santafe1006/100knocks-preprocess/blob/master/zero2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WM3pl7-0pMZU"
      },
      "source": [
        "import sys\r\n",
        "from common.time_layers import *\r\n",
        "from common.np import *\r\n",
        "from common.base_model import BaseModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8-yd4msrPf_"
      },
      "source": [
        "class BetterRnnlm(BaseModel):\r\n",
        "    def __init__(self, vocab_size=10000, wordvec_size=650, hidden_size=650, dropout_ratio=0.5):\r\n",
        "        V, D, H = vocab_size, wordvec_size, hidden_size\r\n",
        "        rn = np.random.randn\r\n",
        "\r\n",
        "        embed_W = (rn(V, D) / 100).astype('f')\r\n",
        "        lstm_Wx1 = (rn(D, 4*H) / np.sqrt(D)).astype('f')\r\n",
        "        lstm_Wh1 =  (rn(H, 4*H) / np.sqrt(H)).astype('f')\r\n",
        "        lstm_Wx2 =  (rn(H, 4*H) / np.sqrt(H)).astype('f')\r\n",
        "        lstm_Wh2 = (rn(H, 4*H) / np.sqrt(H)).astype('f')\r\n",
        "        lstm_b1 = np.zeros(4*H).astype('f')\r\n",
        "        lstm_b2 = np.zeros(4*H).astype('f')\r\n",
        "\r\n",
        "        affine_b = np.zeros(V).astype('f')\r\n",
        "\r\n",
        "        self.layers = [\r\n",
        "                       TimeEmbedding(embed_W),\r\n",
        "                       TimeDropout(dropout_ratio),\r\n",
        "                       TimeLSTM(lstm_Wx1, lstm_Wh1, lstm_b1, stateful=True),\r\n",
        "                       TimeDropout(dropout_ratio),\r\n",
        "                       TimeLSTM(lstm_Wx2, lstm_Wh2, lstm_b2, stateful=True),\r\n",
        "                       TimeDropout(dropout_ratio),\r\n",
        "                       TimeAffine(embed_W.T, affine_b)\r\n",
        "        ]\r\n",
        "        self.loss_layer = TimeSoftmaxWithLoss()\r\n",
        "        self.lstm_layers = [self.layers[2], self.layers[4]]\r\n",
        "        self.drop_layers = [self.layers[1], self.layers[3], self.layers[3]]\r\n",
        "        self.params, self.grads = [], []\r\n",
        "        for layer in self.layers:\r\n",
        "            self.params += layer.params\r\n",
        "            self.grads += layer.grads\r\n",
        "\r\n",
        "    def predict(self, xs, trani_flg=False):\r\n",
        "        for layer in self.drop_layers:\r\n",
        "            layer.train_flg = traing_flg\r\n",
        "        for layer in self.layers:\r\n",
        "            xs = layer.forward(xs)\r\n",
        "        return xs\r\n",
        "\r\n",
        "    def forward(self, xs, ts, train_flg=True):\r\n",
        "        score = self.predict(xs, train_flg)\r\n",
        "        loss = self.loss_layer.forward(score,ts)\r\n",
        "        return loss\r\n",
        "\r\n",
        "    def backward(self, dout=1):\r\n",
        "        dout = self.loss_layer.backward(dout)\r\n",
        "        for layer in reversed(self.layers):\r\n",
        "            dout = layer.backward(dout)\r\n",
        "        return dout\r\n",
        "\r\n",
        "    def reset_state(self):\r\n",
        "        for layer in self.lstm_layers:\r\n",
        "            layer.reset_state()\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0UBKmgMvKWb"
      },
      "source": [
        "from common import config\r\n",
        "config.GPU = True\r\n",
        "from common.optimizer import SGD\r\n",
        "from common.trainer import RnnlmTrainer\r\n",
        "from common.util import eval_perplexity\r\n",
        "from dataset import ptb\r\n",
        "# from better_rnnlm import BetterRnnlm\r\n",
        "\r\n",
        "# set hyper parameter\r\n",
        "batch_size = 20\r\n",
        "wordvec_size = 650\r\n",
        "hidden_size = 650\r\n",
        "time_size = 35\r\n",
        "lr = 20.0\r\n",
        "max_epoch = 40\r\n",
        "max_grad = 0.25\r\n",
        "dropout = 0.5\r\n",
        "\r\n",
        "# load learned data\r\n",
        "corpus, word_to_id, id_to_word = ptb.load_data('train')\r\n",
        "corpus_val, _, _ = ptb.load_data('val')\r\n",
        "corpus_test, _, _ = ptb.load_data('test')\r\n",
        "\r\n",
        "vocab_size = len(word_to_id)\r\n",
        "xs = corpus[:-1]\r\n",
        "ts = corpus[1:]\r\n",
        "\r\n",
        "model = BetterRnnlm(vocab_size, wordvec_size, hidden_size, dropout)\r\n",
        "optimizer = SGD(lr)\r\n",
        "trainer = RnnlmTrainer(model, optimizer)\r\n",
        "\r\n",
        "best_ppl = float('inf')\r\n",
        "for epoch in range(max_epoch):\r\n",
        "    trainer.fit(xs, ts, max_epoch=1, batch_size=batch_size, \r\n",
        "                time_size=time_size, max_grad=max_grad)\r\n",
        "    model.reset_state()\r\n",
        "    ppl = eval_perplexity(model, corpus_val)\r\n",
        "    print('valid perplexity: ', ppl)\r\n",
        "\r\n",
        "    if best_ppl > ppl:\r\n",
        "        best_ppl = ppl\r\n",
        "        model.save_params()\r\n",
        "    else:\r\n",
        "        lr /= 4.0\r\n",
        "        optimizer.lr = lr\r\n",
        "        model.reset_state()\r\n",
        "        print('-' * 50)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrWikhq0zdbg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}